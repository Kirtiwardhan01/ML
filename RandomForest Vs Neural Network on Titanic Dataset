(Source: https://blog.goodaudience.com/introduction-to-random-forest-algorithm-with-python-9efd1d8f0157)
let us use this algorithm in some dataset, 
In our case we will use Kaggleâ€™s titanic survivors dataset that I preprocessed before

from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from keras.callbacks import ModelCheckpoint
from sklearn.metrics import accuracy_score

#Load the preprocessed dataset
dataset = pd.read_csv(r"C:\Users\hp\Desktop\kirtiwardhan\Datasets\TitanicPreprocessed.csv")
dataset.head()

y = dataset['Survived']
X = dataset.drop(['Survived'], axis = 1)

# Split the dataset to trainand test data
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25, random_state=0)

#Set the parameters for the random forest model :
#Hyperparameters of Sklearn Random forest classifier
parameters = {'bootstrap': True,
              'min_samples_leaf': 3,
              'n_estimators': 50, 
              'min_samples_split': 10,
              'max_features': 'sqrt',
              'max_depth': 6,
              'max_leaf_nodes': None}
              
RF_model = RandomForestClassifier()

#Define the model :
RF_model = RandomForestClassifier(**parameters)
RF_model

#Train the model :
RF_model.fit(train_X, train_y)

#Test the trained model on test data :
RF_predictions = RF_model.predict(test_X)

score = accuracy_score(test_y ,RF_predictions)
print(score)    (0.8251121076233184) ~ 83%

##Using Neural Networks:
#Define the model :
# Build a neural network :
NN_model = Sequential()

NN_model.add(Dense(128, input_dim = 68, activation='relu'))
NN_model.add(Dense(256, activation='relu'))
NN_model.add(Dense(256, activation='relu'))
NN_model.add(Dense(256, activation='relu'))
NN_model.add(Dense(1, activation='sigmoid'))
NN_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#Train the model 
Model_nn = NN_model.fit(train_X, train_y, epochs=150, batch_size=64, 
             validation_split = 0.2, callbacks=callbacks_list)

#Test the trained model on test data :
predictions = NN_model.predict(test_X)
# round predictions
rounded = [round(x[0]) for x in predictions]
predictions = rounded
score = accuracy_score(test_y ,predictions)
print(score)   (0.8071748878923767) ~ 81%


